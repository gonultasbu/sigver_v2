{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import scipy.io as sio\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import random\n",
    "from numpy.random import choice\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "from torchvision import transforms as transforms\n",
    "import argparse\n",
    "import pathlib\n",
    "from typing import Dict, Tuple, Any, Optional\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from visdom_logger.logger import VisdomLogger\n",
    "\n",
    "import datasets.util as util\n",
    "from featurelearning.data import TransformDataset\n",
    "import featurelearning.models as models\n",
    "from preprocessing.normalize import crop_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture\n",
    "class SigNet(nn.Module):\n",
    "    \"\"\" SigNet model, from https://arxiv.org/abs/1705.05787\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SigNet, self).__init__()\n",
    "\n",
    "        self.feature_space_size = 2048\n",
    "\n",
    "        self.conv_layers = nn.Sequential(OrderedDict([\n",
    "            ('conv1', conv_bn_relu(1, 96, 11, stride=4)),\n",
    "            ('maxpool1', nn.MaxPool2d(3, 2)),\n",
    "            ('conv2', conv_bn_relu(96, 256, 5, pad=2)),\n",
    "            ('maxpool2', nn.MaxPool2d(3, 2)),\n",
    "            ('conv3', conv_bn_relu(256, 384, 3, pad=1)),\n",
    "            ('conv4', conv_bn_relu(384, 384, 3, pad=1)),\n",
    "            ('conv5', conv_bn_relu(384, 256, 3, pad=1)),\n",
    "            ('maxpool3', nn.MaxPool2d(3, 2)),\n",
    "        ]))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(OrderedDict([\n",
    "            ('fc1', linear_bn_relu(256 * 3 * 5, 2048)),\n",
    "            ('fc2', linear_bn_relu(self.feature_space_size, self.feature_space_size)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv_layers(inputs)\n",
    "        x = x.view(x.shape[0], 256 * 3 * 5)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def conv_bn_relu(in_channels, out_channels, kernel_size,  stride=1, pad=0):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('conv', nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad, bias=False)),\n",
    "        ('bn', nn.BatchNorm2d(out_channels)),\n",
    "        ('relu', nn.ReLU()),\n",
    "    ]))\n",
    "\n",
    "\n",
    "def linear_bn_relu(in_features, out_features):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('fc', nn.Linear(in_features, out_features, bias=False)),  # Bias is added after BN\n",
    "        ('bn', nn.BatchNorm1d(out_features)),\n",
    "        ('relu', nn.ReLU()),\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Dataset that applies a transform on the data points on __get__item.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, transform, transform_index=0):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.transform_index = transform_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.dataset[item]\n",
    "        img = data[self.transform_index]\n",
    "\n",
    "        return tuple((self.transform(img), *data[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(base_model: torch.nn.Module,\n",
    "          classification_layer: torch.nn.Module,\n",
    "          forg_layer: torch.nn.Module,\n",
    "          train_loader: torch.utils.data.DataLoader,\n",
    "          val_loader: torch.utils.data.DataLoader,\n",
    "          device: torch.device,\n",
    "          callback: Optional[VisdomLogger],\n",
    "          args: Any,\n",
    "          logdir: Optional[pathlib.Path]):\n",
    "    \"\"\" Trains a network using either SigNet or SigNet-F loss functions on\n",
    "    https://arxiv.org/abs/1705.05787 (e.q. (1) and (4) on the paper)\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_model: torch.nn.Module\n",
    "        The model architecture that \"extract features\" from signatures\n",
    "    classification_layer: torch.nn.Module\n",
    "        The classification layer (from features to predictions of which user\n",
    "        wrote the signature)\n",
    "    forg_layer: torch.nn.Module\n",
    "        The forgery prediction layer (from features to predictions of whether\n",
    "        the signature is a forgery). Only used in args.forg = True\n",
    "    train_loader: torch.utils.data.DataLoader\n",
    "        Iterable that loads the training set (x, y) tuples\n",
    "    val_loader: torch.utils.data.DataLoader\n",
    "        Iterable that loads the validation set (x, y) tuples\n",
    "    device: torch.device\n",
    "        The device (CPU or GPU) to use for training\n",
    "    callback: VisdomLogger (optional)\n",
    "        A callback to report the training progress\n",
    "    args: Namespace\n",
    "        Extra arguments for training: epochs, lr, lr_decay, lr_decay_times, momentum, weight_decay\n",
    "    logdir: str\n",
    "        Where to save the model and training curves\n",
    "    Returns\n",
    "    -------\n",
    "    Dict (str -> tensors)\n",
    "        The trained weights\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect all parameters that need to be optimizer\n",
    "    parameters = list(base_model.parameters()) + list(classification_layer.parameters())\n",
    "    if args.forg:\n",
    "        parameters.extend(forg_layer.parameters())\n",
    "\n",
    "    # Initialize optimizer and learning rate scheduler\n",
    "    optimizer = optim.SGD(parameters, lr=args.lr, momentum=args.momentum,\n",
    "                          nesterov=True, weight_decay=args.weight_decay)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                             args.epochs // args.lr_decay_times,\n",
    "                                             args.lr_decay)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_params = get_parameters(base_model, classification_layer, forg_layer)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        # Train one epoch; evaluate on validation\n",
    "        train_epoch(train_loader, base_model, classification_layer, forg_layer,\n",
    "                    epoch, optimizer, lr_scheduler, callback, device, args)\n",
    "\n",
    "        val_metrics = test(val_loader, base_model, classification_layer, device, args.forg, forg_layer)\n",
    "        val_acc, val_loss, val_forg_acc, val_forg_loss = val_metrics\n",
    "\n",
    "        # Save the best model only on improvement (early stopping)\n",
    "        if val_acc >= best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_params = get_parameters(base_model, classification_layer, forg_layer)\n",
    "            if logdir is not None:\n",
    "                torch.save(best_params, logdir / 'model_best.pth')\n",
    "\n",
    "        if callback:\n",
    "            callback.scalar('val_loss', epoch + 1, val_loss)\n",
    "            callback.scalar('val_acc', epoch + 1, val_acc)\n",
    "\n",
    "            if args.forg:\n",
    "                callback.scalar('val_forg_loss', epoch + 1, val_forg_loss)\n",
    "                callback.scalar('val_forg_acc', epoch + 1, val_forg_acc)\n",
    "\n",
    "        if args.forg:\n",
    "            print('Epoch {}. Val loss: {:.4f}, Val acc: {:.2f}%,'\n",
    "                  'Val forg loss: {:.4f}, Val forg acc: {:.2f}%'.format(epoch, val_loss,\n",
    "                                                                        val_acc * 100,\n",
    "                                                                        val_forg_loss,\n",
    "                                                                        val_forg_acc * 100))\n",
    "        else:\n",
    "            print('Epoch {}. Val loss: {:.4f}, Val acc: {:.2f}%'.format(epoch, val_loss, val_acc * 100))\n",
    "\n",
    "        if logdir is not None:\n",
    "            current_params = get_parameters(base_model, classification_layer, forg_layer)\n",
    "            torch.save(current_params, logdir / 'model_last.pth')\n",
    "            if callback:\n",
    "                callback.save(logdir / 'train_curves.pickle')\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def copy_to_cpu(weights: Dict[str, Any]):\n",
    "    return OrderedDict([(k, v.cpu()) for k, v in weights.items()])\n",
    "\n",
    "\n",
    "def get_parameters(base_model, classification_layer, forg_layer):\n",
    "    best_params = (copy_to_cpu(base_model.state_dict()),\n",
    "                   copy_to_cpu(classification_layer.state_dict()),\n",
    "                   copy_to_cpu(forg_layer.state_dict()))\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def train_epoch(train_loader: torch.utils.data.DataLoader,\n",
    "                base_model: torch.nn.Module,\n",
    "                classification_layer: torch.nn.Module,\n",
    "                forg_layer: torch.nn.Module,\n",
    "                epoch: int,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                lr_scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "                callback: Optional[VisdomLogger],\n",
    "                device: torch.device,\n",
    "                args: Any):\n",
    "    \"\"\" Trains the network for one epoch\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_loader: torch.utils.data.DataLoader\n",
    "            Iterable that loads the training set (x, y) tuples\n",
    "        base_model: torch.nn.Module\n",
    "            The model architecture that \"extract features\" from signatures\n",
    "        classification_layer: torch.nn.Module\n",
    "            The classification layer (from features to predictions of which user\n",
    "            wrote the signature)\n",
    "        forg_layer: torch.nn.Module\n",
    "            The forgery prediction layer (from features to predictions of whether\n",
    "            the signature is a forgery). Only used in args.forg = True\n",
    "        epoch: int\n",
    "            The current epoch (used for reporting)\n",
    "        optimizer: torch.optim.Optimizer\n",
    "            The optimizer (already initialized)\n",
    "        lr_scheduler: torch.optim.lr_scheduler._LRScheduler\n",
    "            The learning rate scheduler\n",
    "        callback: VisdomLogger (optional)\n",
    "            A callback to report the training progress\n",
    "        device: torch.device\n",
    "            The device (CPU or GPU) to use for training\n",
    "        args: Namespace\n",
    "            Extra arguments used for training:\n",
    "            args.forg: bool\n",
    "                Whether forgeries are being used for training\n",
    "            args.lamb: float\n",
    "                The weight used for the forgery loss (training with forgeries only)\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "    step = 0\n",
    "    n_steps = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x = torch.tensor(x, dtype=torch.float).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        yforg = torch.tensor(batch[2], dtype=torch.float).to(device)\n",
    "\n",
    "        # Forward propagation\n",
    "        features = base_model(x)\n",
    "\n",
    "        if args.forg:\n",
    "            if args.loss_type == 'L1':\n",
    "                # Eq (3) in https://arxiv.org/abs/1705.05787\n",
    "                logits = classification_layer(features)\n",
    "                class_loss = F.cross_entropy(logits, y)\n",
    "\n",
    "                forg_logits = forg_layer(features).squeeze()\n",
    "                forg_loss = F.binary_cross_entropy_with_logits(forg_logits, yforg)\n",
    "\n",
    "                loss = (1 - args.lamb) * class_loss\n",
    "                loss += args.lamb * forg_loss\n",
    "            else: \n",
    "                # Eq (4) in https://arxiv.org/abs/1705.05787\n",
    "                logits = classification_layer(features[yforg == 0])\n",
    "                class_loss = F.cross_entropy(logits, y[yforg == 0])\n",
    "\n",
    "                forg_logits = forg_layer(features).squeeze()\n",
    "                forg_loss = F.binary_cross_entropy_with_logits(forg_logits, yforg)\n",
    "\n",
    "                loss = (1 - args.lamb) * class_loss\n",
    "                loss += args.lamb * forg_loss\n",
    "        else:\n",
    "            # Eq (1) in https://arxiv.org/abs/1705.05787\n",
    "            logits = classification_layer(features)\n",
    "            loss = class_loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        # Back propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(optimizer.param_groups[0]['params'], 10)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        if callback and step % 100 == 0:\n",
    "            iteration = epoch + (step / n_steps)\n",
    "            callback.scalar('class_loss', iteration, class_loss.detach())\n",
    "\n",
    "            pred = logits.argmax(1)\n",
    "            if args.loss_type == 'L1': acc = y.eq(pred).float().mean()\n",
    "            else: acc = y[yforg == 0].eq(pred[yforg == 0]).float().mean()\n",
    "            callback.scalar('train_acc', epoch + (step / n_steps), acc.detach())\n",
    "            if args.forg:\n",
    "                forg_pred = forg_logits > 0\n",
    "                forg_acc = yforg.long().eq(forg_pred.long()).float().mean()\n",
    "                callback.scalar('forg_loss', iteration, forg_loss.detach())\n",
    "                callback.scalar('forg_acc', iteration, forg_acc.detach())\n",
    "\n",
    "        step += 1\n",
    "    lr_scheduler.step()\n",
    "\n",
    "\n",
    "def test(val_loader: torch.utils.data.DataLoader,\n",
    "         base_model: torch.nn.Module,\n",
    "         classification_layer: torch.nn.Module,\n",
    "         device: torch.device,\n",
    "         is_forg: bool,\n",
    "         forg_layer: Optional[torch.nn.Module] = None) -> Tuple[float, float, float, float]:\n",
    "    \"\"\" Test the model in a validation/test set\n",
    "    Parameters\n",
    "    ----------\n",
    "    val_loader: torch.utils.data.DataLoader\n",
    "        Iterable that loads the validation set (x, y) tuples\n",
    "    base_model: torch.nn.Module\n",
    "        The model architecture that \"extract features\" from signatures\n",
    "    classification_layer: torch.nn.Module\n",
    "        The classification layer (from features to predictions of which user\n",
    "        wrote the signature)\n",
    "    device: torch.device\n",
    "        The device (CPU or GPU) to use for training\n",
    "    is_forg: bool\n",
    "        Whether or not forgeries are being used for training/testing\n",
    "    forg_layer: torch.nn.Module\n",
    "            The forgery prediction layer (from features to predictions of whether\n",
    "            the signature is a forgery). Only used in is_forg = True\n",
    "    Returns\n",
    "    -------\n",
    "    float, float\n",
    "        The valication accuracy and validation loss\n",
    "    \"\"\"\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    val_forg_losses = []\n",
    "    val_forg_accs = []\n",
    "    for batch in val_loader:\n",
    "        x, y, yforg = batch[0], batch[1], batch[2]\n",
    "        x = torch.tensor(x, dtype=torch.float).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        yforg = torch.tensor(yforg, dtype=torch.float).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = base_model(x)\n",
    "            logits = classification_layer(features[yforg == 0])\n",
    "\n",
    "            loss = F.cross_entropy(logits, y[yforg == 0])\n",
    "            pred = logits.argmax(1)\n",
    "            acc = y[yforg == 0].eq(pred).float().mean()\n",
    "\n",
    "            if is_forg:\n",
    "                forg_logits = forg_layer(features).squeeze()\n",
    "                forg_loss = F.binary_cross_entropy_with_logits(forg_logits, yforg)\n",
    "                forg_pred = forg_logits > 0\n",
    "                forg_acc = yforg.long().eq(forg_pred.long()).float().mean()\n",
    "\n",
    "                val_forg_losses.append(forg_loss.item())\n",
    "                val_forg_accs.append(forg_acc.item())\n",
    "\n",
    "        val_losses.append(loss.item())\n",
    "        val_accs.append(acc.item())\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = np.mean(val_accs)\n",
    "    val_forg_loss = np.mean(val_forg_losses) if len(val_forg_losses) > 0 else np.nan\n",
    "    val_forg_acc= np.mean(val_forg_accs) if len(val_forg_accs) > 0 else np.nan\n",
    "\n",
    "    if is_forg: return val_acc.item(), val_loss.item(), val_forg_acc.item(), val_forg_loss.item()\n",
    "    else : return val_acc.item(), val_loss.item(), val_forg_acc, val_forg_loss\n",
    "\n",
    "def setup_data_loaders(data, batch_size, input_size):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(data[1])\n",
    "    data = TensorDataset(torch.from_numpy(data[0]), torch.from_numpy(y), torch.from_numpy(data[2]))\n",
    "    train_size = int(0.9 * len(data))\n",
    "    sizes = (train_size, len(data) - train_size)\n",
    "    train_set, test_set = random_split(data, sizes)\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_set = TransformDataset(train_set, train_transforms)\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    test_set = TransformDataset(test_set, val_transforms)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def main(args):\n",
    "    # Setup logging\n",
    "    logdir = pathlib.Path(args.logdir)\n",
    "    if not logdir.exists():\n",
    "        logdir.mkdir()\n",
    "\n",
    "    if args.visdomport is not None:\n",
    "        logger = VisdomLogger(port=args.visdomport)\n",
    "    else:\n",
    "        logger = None\n",
    "\n",
    "    device = torch.device('cuda', args.gpu_idx) if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print('Using device: {}'.format(device))\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    print('Loading Data')\n",
    "\n",
    "    x, y, yforg, usermapping, filenames = util.load_dataset(args.dataset_path)\n",
    "    data = util.get_subset((x, y, yforg), subset=range(*args.users))\n",
    "    if not args.forg:\n",
    "        data = util.remove_forgeries(data, forg_idx=2)\n",
    "\n",
    "    train_loader, val_loader = setup_data_loaders(data, args.batch_size, args.input_size)\n",
    "\n",
    "    print('Initializing Model')\n",
    "\n",
    "    n_classes = len(np.unique(data[1]))\n",
    "\n",
    "    base_model = models.available_models[args.model]().to(device)\n",
    "    classification_layer = nn.Linear(base_model.feature_space_size, n_classes).to(device)\n",
    "    if args.forg:\n",
    "        forg_layer = nn.Linear(base_model.feature_space_size, 1).to(device)\n",
    "    else:\n",
    "        forg_layer = nn.Module()  # Stub module with no parameters\n",
    "\n",
    "    if args.test:\n",
    "        print('Testing')\n",
    "        base_model_params, classification_params, forg_params = torch.load(args.checkpoint)\n",
    "        base_model.load_state_dict(base_model_params)\n",
    "\n",
    "        classification_layer.load_state_dict(classification_params)\n",
    "        if args.forg:\n",
    "            forg_layer.load_state_dict(forg_params)\n",
    "        val_acc, val_loss, val_forg_acc, val_forg_loss = test(val_loader, base_model, classification_layer,\n",
    "                                                              device, args.forg, forg_layer)\n",
    "        if args.forg:\n",
    "            print('Val loss: {:.4f}, Val acc: {:.2f}%,'\n",
    "                  'Val forg loss: {:.4f}, Val forg acc: {:.2f}%'.format(val_loss,\n",
    "                                                                        val_acc * 100,\n",
    "                                                                        val_forg_loss,\n",
    "                                                                        val_forg_acc * 100))\n",
    "        else:\n",
    "            print('Val loss: {:.4f}, Val acc: {:.2f}%'.format(val_loss, val_acc * 100))\n",
    "\n",
    "    else:\n",
    "        print('Training')\n",
    "        train(base_model, classification_layer, forg_layer, train_loader, val_loader,\n",
    "              device, logger, args, logdir)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(args, model):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device: {}'.format(device))\n",
    "    npz_dir = args.extraction_path\n",
    "    with np.load(npz_dir, allow_pickle=True) as data:\n",
    "        x, y, yforg, user_mapping, filenames = data['x'], data['y'], data['yforg'], data['user_mapping'], data['filenames']\n",
    "    xc = np.zeros((x.shape[0],1,150,220), dtype=np.uint8)\n",
    "    for idx in tqdm.tqdm(np.arange(x.shape[0]),ascii=True):\n",
    "        xc[idx,0,:,:] = crop_center(x[idx,0,:,:], (150,220))\n",
    "    del x \n",
    "    visual_f=np.zeros((xc.shape[0],2048))\n",
    "    with torch.no_grad():\n",
    "        for idx,gpu_slice in enumerate(np.split(xc,250)):\n",
    "            visual_f[idx*len(gpu_slice):(idx+1)*len(gpu_slice),:] = base_model(torch.tensor(gpu_slice).float().div(255).to(device)).cpu()\n",
    "    visual_f = pd.DataFrame(visual_f)\n",
    "    if npz_dir.endswith('gpds4k.npz'):\n",
    "        sig_ids = np.array([int(fname.lower().split('-')[-1].split('.')[0]) for fname in np.squeeze(filenames)])\n",
    "        user_ids = np.array([int(fname.lower().split('-')[1]) for fname in np.squeeze(filenames)])\n",
    "    elif npz_dir.endswith('mcyt.npz'):\n",
    "        user_ids = np.array([int(fname.lower().split('_')[-1].split('v')[0].split('f')[0]) for fname in np.squeeze(filenames)])\n",
    "        sig_ids = np.array([int(fname.lower().split('_')[-1].split('v')[-1].split('f')[-1].split('.')[0])+1 for fname in np.squeeze(filenames)])\n",
    "    filenames_ex = np.expand_dims(filenames,axis=1)\n",
    "    yforg_ex = np.expand_dims(yforg,axis=1)\n",
    "    sig_ids_ex = np.expand_dims(sig_ids,axis=1)\n",
    "    user_ids_ex = np.expand_dims(user_ids,axis=1)    \n",
    "    data_f=pd.DataFrame(np.concatenate((filenames_ex, user_ids_ex, sig_ids_ex, yforg_ex),axis=1), columns=['path', 'user_id', 'sig_id', 'fakeness'])\n",
    "    return visual_f, data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training params here.\n",
    "class argstore:\n",
    "    def __init__(self):\n",
    "        self.dataset_path = 'C:\\\\Users\\\\Mert\\\\Documents\\\\GitHub\\\\sigver_v2\\\\npz\\\\gpds4k.npz'\n",
    "        self.input_size = (150,220)\n",
    "        self.users = (1201,4000)\n",
    "        self.model = 'signet'\n",
    "        self.batch_size = 32\n",
    "        self.lr = 1e-3\n",
    "        self.lr_decay = 0.1\n",
    "        self.lr_decay_times = 3.0\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 1e-4\n",
    "        self.epochs = 60\n",
    "        '''\n",
    "        self.checkpoint = []\n",
    "        '''\n",
    "        self.test = False\n",
    "        self.seed = 42\n",
    "        self.forg = False\n",
    "        '''\n",
    "        self.lamb = 0\n",
    "        '''\n",
    "        self.loss_type = 'L2'\n",
    "        self.gpu_idx = 0\n",
    "        self.logdir = 'default_logdir'\n",
    "        self.visdomport = None\n",
    "        self.extraction_path = 'C:\\\\Users\\\\Mert\\\\Documents\\\\GitHub\\\\sigver_v2\\\\npz\\\\gpds4k.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading Data\n",
      "Initializing Model\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:250: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "c:\\users\\mert\\anaconda3\\envs\\ml_gpu\\lib\\site-packages\\ipykernel_launcher.py:252: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Val loss: 6.5265, Val acc: 2.02%\n",
      "Epoch 1. Val loss: 5.6090, Val acc: 12.57%\n",
      "Epoch 2. Val loss: 4.8099, Val acc: 24.98%\n",
      "Epoch 3. Val loss: 4.0737, Val acc: 38.09%\n",
      "Epoch 4. Val loss: 3.3784, Val acc: 50.57%\n",
      "Epoch 5. Val loss: 2.7551, Val acc: 62.17%\n",
      "Epoch 6. Val loss: 2.2081, Val acc: 71.90%\n",
      "Epoch 7. Val loss: 1.7660, Val acc: 78.22%\n",
      "Epoch 8. Val loss: 1.3649, Val acc: 83.85%\n",
      "Epoch 9. Val loss: 1.0909, Val acc: 87.53%\n",
      "Epoch 10. Val loss: 0.8700, Val acc: 90.73%\n",
      "Epoch 11. Val loss: 0.7093, Val acc: 92.08%\n",
      "Epoch 12. Val loss: 0.5961, Val acc: 93.96%\n",
      "Epoch 13. Val loss: 0.5001, Val acc: 94.69%\n",
      "Epoch 14. Val loss: 0.4347, Val acc: 95.34%\n",
      "Epoch 15. Val loss: 0.3825, Val acc: 95.94%\n",
      "Epoch 16. Val loss: 0.3450, Val acc: 96.28%\n",
      "Epoch 17. Val loss: 0.3055, Val acc: 96.67%\n",
      "Epoch 18. Val loss: 0.2770, Val acc: 97.01%\n",
      "Epoch 19. Val loss: 0.2583, Val acc: 97.29%\n",
      "Epoch 20. Val loss: 0.2314, Val acc: 97.78%\n",
      "Epoch 21. Val loss: 0.2145, Val acc: 97.78%\n",
      "Epoch 22. Val loss: 0.2041, Val acc: 97.88%\n",
      "Epoch 23. Val loss: 0.1928, Val acc: 98.02%\n",
      "Epoch 24. Val loss: 0.1796, Val acc: 98.26%\n",
      "Epoch 25. Val loss: 0.1698, Val acc: 98.23%\n",
      "Epoch 26. Val loss: 0.1688, Val acc: 98.26%\n",
      "Epoch 27. Val loss: 0.1676, Val acc: 98.37%\n",
      "Epoch 28. Val loss: 0.1659, Val acc: 98.40%\n",
      "Epoch 29. Val loss: 0.1653, Val acc: 98.44%\n",
      "Epoch 30. Val loss: 0.1643, Val acc: 98.37%\n",
      "Epoch 31. Val loss: 0.1639, Val acc: 98.40%\n",
      "Epoch 32. Val loss: 0.1624, Val acc: 98.47%\n",
      "Epoch 33. Val loss: 0.1613, Val acc: 98.54%\n",
      "Epoch 34. Val loss: 0.1614, Val acc: 98.47%\n",
      "Epoch 35. Val loss: 0.1604, Val acc: 98.51%\n",
      "Epoch 36. Val loss: 0.1595, Val acc: 98.51%\n",
      "Epoch 37. Val loss: 0.1595, Val acc: 98.47%\n",
      "Epoch 38. Val loss: 0.1584, Val acc: 98.44%\n",
      "Epoch 39. Val loss: 0.1582, Val acc: 98.51%\n",
      "Epoch 40. Val loss: 0.1574, Val acc: 98.58%\n",
      "Epoch 41. Val loss: 0.1573, Val acc: 98.47%\n",
      "Epoch 42. Val loss: 0.1563, Val acc: 98.47%\n",
      "Epoch 43. Val loss: 0.1560, Val acc: 98.44%\n",
      "Epoch 44. Val loss: 0.1551, Val acc: 98.47%\n",
      "Epoch 45. Val loss: 0.1544, Val acc: 98.47%\n",
      "Epoch 46. Val loss: 0.1538, Val acc: 98.51%\n",
      "Epoch 47. Val loss: 0.1539, Val acc: 98.61%\n",
      "Epoch 48. Val loss: 0.1523, Val acc: 98.58%\n",
      "Epoch 49. Val loss: 0.1527, Val acc: 98.47%\n",
      "Epoch 50. Val loss: 0.1520, Val acc: 98.51%\n",
      "Epoch 51. Val loss: 0.1518, Val acc: 98.54%\n",
      "Epoch 52. Val loss: 0.1517, Val acc: 98.51%\n",
      "Epoch 53. Val loss: 0.1516, Val acc: 98.47%\n",
      "Epoch 54. Val loss: 0.1515, Val acc: 98.51%\n",
      "Epoch 55. Val loss: 0.1514, Val acc: 98.54%\n",
      "Epoch 56. Val loss: 0.1513, Val acc: 98.58%\n",
      "Epoch 57. Val loss: 0.1513, Val acc: 98.54%\n",
      "Epoch 58. Val loss: 0.1512, Val acc: 98.54%\n",
      "Epoch 59. Val loss: 0.1512, Val acc: 98.54%\n",
      "Epoch 60. Val loss: 0.1511, Val acc: 98.58%\n",
      "Epoch 61. Val loss: 0.1512, Val acc: 98.58%\n",
      "Epoch 62. Val loss: 0.1511, Val acc: 98.51%\n",
      "Epoch 63. Val loss: 0.1511, Val acc: 98.51%\n",
      "Epoch 64. Val loss: 0.1510, Val acc: 98.51%\n",
      "Epoch 65. Val loss: 0.1509, Val acc: 98.51%\n",
      "Epoch 66. Val loss: 0.1507, Val acc: 98.54%\n",
      "Epoch 67. Val loss: 0.1507, Val acc: 98.58%\n",
      "Epoch 68. Val loss: 0.1506, Val acc: 98.58%\n",
      "Epoch 69. Val loss: 0.1507, Val acc: 98.61%\n",
      "Epoch 70. Val loss: 0.1507, Val acc: 98.61%\n",
      "Epoch 71. Val loss: 0.1506, Val acc: 98.54%\n",
      "Epoch 72. Val loss: 0.1505, Val acc: 98.54%\n",
      "Epoch 73. Val loss: 0.1505, Val acc: 98.58%\n",
      "Epoch 74. Val loss: 0.1504, Val acc: 98.58%\n"
     ]
    }
   ],
   "source": [
    "args = argstore()\n",
    "base_model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#######################################################################| 216000/216000 [00:03<00:00, 55249.36it/s]\n"
     ]
    }
   ],
   "source": [
    "visual_f, data_f = feature_extraction(args, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess to convert strings to integers.\n",
    "data_f['user_id']=data_f['user_id'].astype('int32')\n",
    "data_f['sig_id']=data_f['sig_id'].astype('int8')\n",
    "data_f['fakeness']=data_f['fakeness'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_KERNEL='rbf'\n",
    "TRAIN_ITERATIONS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_exp_ratio = 0.30\n",
    "sorted_id_list = np.sort(data_f['user_id'].unique())\n",
    "dev_exp_splitter=int(len(sorted_id_list)*dev_exp_ratio)\n",
    "dev_val_user_ids = sorted_id_list[:dev_exp_splitter]\n",
    "exp_user_ids = sorted_id_list[dev_exp_splitter:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|################################################################################| 200/200 [17:58<00:00,  6.11s/it]\n"
     ]
    }
   ],
   "source": [
    "fakes_preds = []\n",
    "gens_preds = []\n",
    "\n",
    "for fold in np.arange(0,TRAIN_ITERATIONS):\n",
    "    # assert len(dev_val_user_ids)==581\n",
    "    np.random.shuffle(dev_val_user_ids)\n",
    "    dev_user_ids = dev_val_user_ids[0:1000]\n",
    "    validation_user_ids = dev_val_user_ids[1000:len(dev_val_user_ids)]\n",
    "    train_idx, test_idx = train_test_split(np.arange(1,25), train_size=0.5, test_size=0.5)\n",
    "\n",
    "    dev_df = data_f.loc[data_f['user_id'].isin(dev_user_ids)]\n",
    "    dev_vf = visual_f.loc[dev_df.index]\n",
    "    val_df = data_f.loc[data_f['user_id'].isin(validation_user_ids)]\n",
    "    val_vf = visual_f.loc[val_df.index]\n",
    "\n",
    "    dev_df_gen = dev_df.loc[dev_df['fakeness']==0]\n",
    "    dev_df_fake = dev_df.loc[dev_df['fakeness']==1]\n",
    "    dev_df_gen_12 = dev_df_gen.loc[dev_df_gen['sig_id'].isin(train_idx)]\n",
    "    dev_df_valid_12 = dev_df_gen.loc[dev_df_gen['sig_id'].isin(test_idx)]\n",
    "    \n",
    "    train_idx, test_idx = train_test_split(np.arange(1,25), train_size=0.5)\n",
    "    val_df_gen = val_df.loc[val_df['fakeness']==0]\n",
    "    val_df_fake = val_df.loc[val_df['fakeness']==1]\n",
    "    val_df_gen_12 = val_df_gen.loc[val_df_gen['sig_id'].isin(train_idx)]\n",
    "    val_df_valid_gen_12 = val_df_gen.loc[val_df_gen['sig_id'].isin(test_idx)]\n",
    "\n",
    "    for user_id in tqdm.tqdm(validation_user_ids, ascii=True):\n",
    "        clf = SVC(C=1,gamma='scale',class_weight='balanced', probability=False, kernel=USER_KERNEL)\n",
    "        y_train = (pd.concat([val_df_gen_12.loc[val_df_gen_12['user_id']==user_id],dev_df_gen.loc[dev_df_gen['user_id']!=user_id]]))['user_id']==user_id\n",
    "        X_train = visual_f.loc[y_train.index]  \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_valid_fakes = val_df_fake.loc[(val_df_fake['user_id']==user_id)]\n",
    "        X_valid_f = visual_f.loc[y_valid_fakes.index]\n",
    "        fakes_preds.append(clf.decision_function(X_valid_f))\n",
    "        y_valid_gens = val_df_valid_gen_12.loc[val_df_valid_gen_12['user_id']==user_id]\n",
    "        X_valid_g = visual_f.loc[y_valid_gens.index]\n",
    "        gens_preds.append(clf.decision_function(X_valid_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER_glob :  7.449999999999999 \n",
      "EER_Threshold_glob :  -0.07249462839458398\n"
     ]
    }
   ],
   "source": [
    "flat_fakes_preds = np.expand_dims(np.array([item for sublist in fakes_preds for item in sublist]),axis=1)\n",
    "flat_gens_preds = np.expand_dims(np.array([item for sublist in gens_preds for item in sublist]),axis=1)\n",
    "all_preds = np.vstack((flat_fakes_preds,flat_gens_preds))\n",
    "all_labels = np.vstack((np.zeros((flat_fakes_preds.shape[0],1)),np.ones((flat_gens_preds.shape[0],1))))\n",
    "\n",
    "fpr,tpr,threshold = roc_curve(all_labels,all_preds)\n",
    "fnr = 1 - tpr\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "eer_th = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print('EER_glob : ', EER*100,'\\nEER_Threshold_glob : ', eer_th)\n",
    "glob_th = eer_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER_user :  3.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "assert len(fakes_preds)==len(gens_preds)\n",
    "EER_accum=0\n",
    "for idx,val in enumerate(fakes_preds):\n",
    "    user_fakes_preds = np.expand_dims(np.array(fakes_preds[idx]),axis=1)\n",
    "    user_gens_preds = np.expand_dims(np.array(gens_preds[idx]),axis=1)\n",
    "    all_user_preds = np.vstack((user_fakes_preds,user_gens_preds))\n",
    "    all_user_labels = np.vstack((np.zeros((user_fakes_preds.shape[0],1)),np.ones((user_gens_preds.shape[0],1)))) \n",
    "    fpr,tpr,threshold = roc_curve(all_user_labels,all_user_preds)\n",
    "    fnr = 1 - tpr\n",
    "    EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    EER_accum += EER\n",
    "    \n",
    "print('EER_user : ', (EER_accum*100)/len(fakes_preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07249462839458398\n"
     ]
    }
   ],
   "source": [
    "print(glob_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
